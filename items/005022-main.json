{
  "url": "https://api.github.com/repos/rust-lang/rust/issues/5022",
  "repository_url": "https://api.github.com/repos/rust-lang/rust",
  "labels_url": "https://api.github.com/repos/rust-lang/rust/issues/5022/labels{/name}",
  "comments_url": "https://api.github.com/repos/rust-lang/rust/issues/5022/comments",
  "events_url": "https://api.github.com/repos/rust-lang/rust/issues/5022/events",
  "html_url": "https://github.com/rust-lang/rust/pull/5022",
  "id": 11137704,
  "node_id": "MDExOlB1bGxSZXF1ZXN0NDIwMTUzMw==",
  "number": 5022,
  "title": "A new scheduler prototype",
  "user": {
    "login": "brson",
    "id": 147214,
    "node_id": "MDQ6VXNlcjE0NzIxNA==",
    "avatar_url": "https://avatars.githubusercontent.com/u/147214?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/brson",
    "html_url": "https://github.com/brson",
    "followers_url": "https://api.github.com/users/brson/followers",
    "following_url": "https://api.github.com/users/brson/following{/other_user}",
    "gists_url": "https://api.github.com/users/brson/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/brson/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/brson/subscriptions",
    "organizations_url": "https://api.github.com/users/brson/orgs",
    "repos_url": "https://api.github.com/users/brson/repos",
    "events_url": "https://api.github.com/users/brson/events{/privacy}",
    "received_events_url": "https://api.github.com/users/brson/received_events",
    "type": "User",
    "user_view_type": "public",
    "site_admin": false
  },
  "labels": [],
  "state": "closed",
  "locked": false,
  "assignee": null,
  "assignees": [],
  "milestone": null,
  "comments": 1,
  "created_at": "2013-02-19T01:13:38Z",
  "updated_at": "2014-06-12T21:35:10Z",
  "closed_at": "2013-03-07T01:00:35Z",
  "author_association": "CONTRIBUTOR",
  "type": null,
  "active_lock_reason": null,
  "draft": false,
  "pull_request": {
    "url": "https://api.github.com/repos/rust-lang/rust/pulls/5022",
    "html_url": "https://github.com/rust-lang/rust/pull/5022",
    "diff_url": "https://github.com/rust-lang/rust/pull/5022.diff",
    "patch_url": "https://github.com/rust-lang/rust/pull/5022.patch",
    "merged_at": null
  },
  "body": "This is a prototype task scheduler, written in Rust, that is driven by an abstract event loop, along with the beginnings of an I/O interface for translating asynchronous I/O to synchronous I/O via scheduler context switches. It is part of issue #4419.\n\nIt is not ready to merge, but this is an opportunity to review and discuss.\n\nWhile I am primarily interested in proving the integration of I/O with the scheduler, this is also written with a number of other goals in mind:\n- Replacing C++ code with Rust\n- Clean up stack management (#2044, #4479, #4480)\n- Supporting the work stealing algorithm (#3095)\n- Do much less synchronization in some scheduling scenarios (particularly involving I/O, but also possibly spawning, sending, etc.).\n- Simplifying the lifecycle and multithreading complexity of runtime types\n\nWhat is implemented:\n- Context switching operations (scheduler->task, task->scheduler, task->task, blocking)\n- An opaque event loop and I/O abstraction using objects\n- Safer uv bindings that build on std::uv::ll\n- Very simple TCP reads and writes\n\nUnimplemented:\n- Anything related to multithreading\n- Much I/O, including dealing with any cases where a task isn't available to respond to an I/O event\n- Platforms other than x864_64 and unix\n## Scheduler design\n\nI am trying to use ownership to make the relationships between scheduler types clear, and as a result this scheduler is structured quite differently than the current one.\n\nThe core idea here is that tasks are owned, and code that owns a task is free to schedule it. During the lifetime of a task ownership transfers between schedulers and objects on which the task is blocked. The state of a task (blocked vs. running vs. dead, etc.) is encoded in its ownership.\n\nFor comparison, in the existing scheduler, the task is (basically) owned by a scheduler, but is atomically reference counted so other entities (like pipes that a task is blocked on) occasionally hold pointers to a task. The resulting task lifecycle is quite complicated, and I think unnecessarily so.\n\nI believe this model works with pipes very well, though I don't have a complete understanding of pipes yet.\n\nYou'll notice this code is still written as a very big [test case](https://github.com/brson/rust/blob/newsched/src/test/run-pass/newrt.rs), for ease of development.\n\nThe most important submodules:\n- [rt::sched](https://github.com/brson/rust/blob/newsched/src/test/run-pass/newrt_sched.rs) - The core of the scheduler, containing both `Scheduler` and `Task`\n- [rt::uv](https://github.com/brson/rust/blob/newsched/src/test/run-pass/newrt_uv.rs) - libuv bindings that build on uv::ll\n- [rt::io](https://github.com/brson/rust/blob/newsched/src/test/run-pass/newrt_io.rs) - The runtime's abstract I/O interface, implemented for a specific event loop\n- [rt::uvio](https://github.com/brson/rust/blob/newsched/src/test/run-pass/newrt_uvio.rs) - The implementation of `io` for libuv\n\nIn this iteration, `Scheduler` is very simple, mostly providing a few context switching primitive operations, and I like that, so I'll probably break it into multiple types, one as currently written, another dealing with scheduler policy and multithreading. In regards to multithreading, Schedulers are intended to be implemented as actors, mostly dealing with single-threaded state, then occasionally communicating with other schedulers through messages (the current implementation relies more on shared state, locks and signals).\n\n`rt::io` is the runtime's internal, abstract I/O interface. It is used entirely as opaque ~objects and is intended to support yet other, user-facing I/O modules. The I/O interface here should be considered a proof-of-concept, as a real design will require a lot of consideration.\n## Measurements\n\nI've only done one very [simple measurement](https://gist.github.com/brson/4974294), comparing pure TCP read performance between node 0.6 and this scheduler. They indicate this code is about on par with node. I take that as a good sign, though you might expect us to beat node with their dynamic language overhead and the various extra abstractions in their libraries compared to this simple Rust code. perf indicates we spend about 50% time in the kernel, then the usual suspects: `upcall_call_shim_on_c_stack`, `pthread_getspecific`, `malloc` - things that can be tackled in increments.\n\n_Note: The Rust code used a much smaller buffer than node likely is. Adjusting the buffer size to 64K reduces the userspace time significantly._\n## Concerns\n### ~objects don't work\n\nI don't actually remember if I tested them or not, but AIUI they don't work correctly, so I've inserted some placeholder typedefs to try to make the code look like it's using objects when it is not. Hopefully it won't be too hard to do the conversion. Until ~objects works uv needs to live in core.\n### Allocation\n\nThere are a lot of small allocations here, particularly in the uv bindings, which rely heavily on owned closures, but also in the `io` interface that uses objects. Because it is much more pleasant to just use closures everywhere than figure out exactly how to thread data around without allocating, I think this tradeoff is good in the short term. The particularly bad allocations can be optimized as needed. The ~object allocations are considerably harder to eliminate.\n### What happens when I/O types are sent?\n\nWe talked about this in the meeting last week and it's a big problem. I think now that I/O types (those defined in `rt::io` and that form the basis for any I/O API's) must be sendable, the reason being that one-connection per task is going to be the right way to do networking, at least for the near future. The basic server will `listen`, `accept` then capture the connection in a new task.\n\nSo, assuming that I/O types are sendable, there is going to be a lot of complexity in making those I/O types ensure that the task they are _currently_ associated with is running on the correct scheduler. Importantly, task pinning is not sufficient, since the I/O types are bound to a specific _scheduler_ not _task_. Nor will it be sufficient to simply fail if an I/O type migrates to the wrong scheduler, because we have no way to prevent it from happening accidentally (that I can see). It's going to be ugly, and could involve polluting our nice single-threaded I/O paths with some concessions to memory synchronization.\n### Selecting\n\nRelated to the above point about one connection per task, we need to be able to make `select` work with various I/O requests, particularly for reading and listening. Not only that, they have to be able to select on both pipes and I/O types simultaneously (so that I can both listen for incoming connections as well as a signal to _stop_ listening for incoming connections). I have no idea yet how to do this, nor do I even know how pipes implements this currently.\n### Adapting work stealing to non-strict parallel computations\n\nThe work stealing algorithm described in 'Scheduling Multithreaded Computations by Work Stealing' is for 'strict' computations (fork/join style), which is not what we have. We can do something add-hoc to add randomness but I'd rather\nhave something known to work. I do think the work stealing approach makes a lot of sense for us, especially now where we have I/O callbacks that need to be scheduled with high-priority (so cold CPU-bound tasks get stolen to schedulers not doing I/O).\n### Fairness and I/O timeouts\n\nRight now we have a model that does not enforce any sort of time accounting. I kind of like this for performance and simplicity, but it means we can mix CPU bound and I/O bound tasks on a single scheduler without ever yielding to do I/O. I suspect with this merging of I/O and the scheduler we are going to end up wanting some utility functions for setting up groups of schedulers specifically for I/O or specifically for processing.\n## Next\n\nThe immediate goal, pending feedback, will be to get this patch into core. Beyond that there are a number of parallel development paths, primarily I/O design, multithreading and integration.\n### Begin working on user-facing I/O library (#4248)\n\nThis just barely scratches the surface of I/O. Designing an I/O library is itself a huge effort. I think I would like to approach this top down, figure out how we want a synchronous I/O library to be designed, then how to connect it to uv through `rt::io`.\n\nWhen doing this design it's important to consider Rust's unique constraints, in particular the relationship of pipes and the scheduler to I/O. Pipes and I/O readers/writers share a lot in common and need to interoperate in various ways (particularly with `select`). We also need to consider this in the context of the existing `core::io` - what is or isn't working there.\n\nI'm no expert on I/O libraries so I think I'd like to hash this out on the mailing lists, perhaps in conjunction with a survey of other languages' I/O.\n### Multithreading\n- Create a parallel deque (#4877)\n- Port pipes to this scheduler (#5018)\n- Encapsulate scheduling 'policy' in one place (SchedulerPolicy) - so we can experiment easily\n- Teach schedulers to communicate and steal work\n### Integration\n- Fix ~object and convert code to use it\n- Rewrite net::ip to not use uv (#4956)\n- Move uv to core or its own crate (#5019)\n- Context switching for remaining platforms (#5020)\n- `start` lang item (#3406) - so we can start running test cases on this scheduler\n- Bindings for win32 TLS - this only has pthread bindings\n- Stack growth and stack switching - this time stack logic goes into `rt::stack` and not into the task itself. Start by adapting the current scheme to the new scheduler, but consider potential upcoming changes to the FFI.\n- Logging (#5021) - Figure out how to make logging work in global, scheduler, and task context, in the old runtime or in this runtime. Optional complete redesign (#3309).\n- Add the local heap - It can start as just a wrapper for `memory_region`.\n\nI want to hold off on adding linked failure because I think the current design is too complex still, and the implementation imposes some undesirable constraints on the scheduler.\n",
  "closed_by": {
    "login": "brson",
    "id": 147214,
    "node_id": "MDQ6VXNlcjE0NzIxNA==",
    "avatar_url": "https://avatars.githubusercontent.com/u/147214?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/brson",
    "html_url": "https://github.com/brson",
    "followers_url": "https://api.github.com/users/brson/followers",
    "following_url": "https://api.github.com/users/brson/following{/other_user}",
    "gists_url": "https://api.github.com/users/brson/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/brson/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/brson/subscriptions",
    "organizations_url": "https://api.github.com/users/brson/orgs",
    "repos_url": "https://api.github.com/users/brson/repos",
    "events_url": "https://api.github.com/users/brson/events{/privacy}",
    "received_events_url": "https://api.github.com/users/brson/received_events",
    "type": "User",
    "user_view_type": "public",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/rust-lang/rust/issues/5022/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/rust-lang/rust/issues/5022/timeline",
  "performed_via_github_app": null,
  "state_reason": null,
  "_meta": {
    "type": "pr"
  }
}
